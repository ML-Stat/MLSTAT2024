---
title: "Large Models and Graph Structures"
summary: "1:30 p.m. — 3:00 p.m., Friday, Aug. 23, 2024"
tags: "s1-1"
weight: 12
---

Friday, Aug. 23, 2024
------


<hr style="border: 0; border-top: 5px solid;">

<div class="tip">
    <img class="icon" src="/images/yanjiang.png" />
    Session: <span class="font-bold" style="font-size:120%">Large Models and Graph Structures</span>
</div>

<div class="tip">
    <img class="icon" src="/images/shizhong.png" />
    Time: 1:30 p.m. — 3:00 p.m.
</div>
<div class="tip">
    <img class="icon" src="/images/didian.png" />
    Location: Northeast Normal University Free Campus Weizhen Building
</div>


<div class="tip">
    <img class="icon" src="/images/lingdao.png" />
    Session Chair: Zhewei Wei
</div>

________________________________________

<html>
<head>
    <title>Large Models and Graph Structures</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            /* padding: 20px; */
            background-color: #f5f5f5;
        }
        .row {
            display: flex;
            justify-content: center;
        }
        .container {
            max-width: 800px;
            background-color: #ffffff;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 20px;
            margin: 10px;
        }
        .name-bar {
            font-size: 24px;
            font-weight: bold;
            color: #333;
            margin-bottom: 10px;
        }
        .institute {
            font-size: 18px;
            color: #333;
            margin-bottom: 10px;
        }
        .title {
            font-size: 20px;
            text-decoration: underline;
            margin-bottom: 10px;
        }
        .abstract {
            font-size: 20px;
            margin-bottom: 20px;
        }
    </style>
</head>
<body>
    <div class="row">
        <div class="container">
            <div class="name-bar">Jun Zhu</div>
            <div class="institute">Computer Department of Tsinghua University</div>
            <div class="title">Title: 扩散概率模型的前沿进展</div>
            <div class="abstract">
                <strong>Abstract:</strong> AIGC发展迅速，扩散概率模型是AIGC的关键技术之一，在跨模态的文图生成、3D生成、视频生成等方面取得显著进展。该报告将介绍扩散概率模型的若干进展，包括扩散概率模型的基础理论和高效算法、大规模多模态扩散模型、文到3D生成、文到视频生成等内容。
            </div>
            <div class="abstract">
                <strong>CV:</strong> 个人简介：朱军，清华大学计算机系博世AI教授、清华大学人工智能研究院副院长、IEEE/AAAI Fellow。2001到2009年获清华大学计算机学士和博士学位，之后在CMU做博士后和项目科学家，2011年回清华任教，2015到2018年任卡内基梅隆大学兼职教授。主要从事机器学习基础理论、高效算法及应用研究，在国际重要期刊与会议发表论文百余篇。担任顶级期刊IEEE TPAMI的副主编和编委、AI编委，担任ICML、NeurIPS、ICLR、IJCAI、AAAI等国际会议的资深领域主席、地区联合主席、评奖委员会委员、研讨会主席等20余次。获求是杰出青年奖、科学探索奖、吴文俊人工智能自然科学一等奖、CCF自然科学一等奖、ICLR杰出论文奖、ICME/IEEE CoG最佳论文奖等，入选国家高层次人才计划、MIT TR35中国先锋者以及IEEE Intelligent Systems评选的“AI’s 10 to Watch”。研制Vidu视频大模型，以及开源的“珠算”深度概率编程库和“天授”强化学习库。
            </div>
        </div>
    </div>
    <div class="row">
        <div class="container">
            <div class="name-bar">Ruihua Song</div>
            <div class="institute">College of Artificial Intelligence, Renmin University of China</div>
            <div class="title">Title: 做活的AI</div>
            <div class="abstract">
                <strong>Abstract:</strong> 人之所以为人，在认识世界、创造新知、与人与世界交互方面有独特之处。在这个讲座中，我会介绍多模态理解、创作和交互方向最新的研究成果，梳理通用人工智能领域发展的脉络，并探讨做一个活的AI还差什么，图灵测试是否已经过时，如果过时应该用什么来取代等有趣的问题。
            </div>
            <div class="abstract">
                <strong>CV:</strong> 宋睿华博士，国家高层次人才特聘教授，现任中国人民大学高瓴人工智能学院长聘副教授。曾任微软亚洲研究院主管研究员、微软小冰首席科学家。近期研究兴趣为多模态理解、创作和交互。发表学术论文100余篇，申请专利30余项。曾获WWW 2004最佳论文提名奖，AIRS 2012最佳论文奖，和CLWS 2019优秀论文奖，2022年度教育部自然科学一等奖。她的算法完成了人类史上第一本人工智能创作的诗集《阳光失了玻璃窗》。2021-2022年作为学术带头人，发布文澜系列中文多模态对齐大模型，并成功落地快手、OPPO等企业。2023年，参与发布玉兰大语言模型，完成从基础模型到对话模型的自研训练。曾担任SIGIR短文和讲习班主席，ACL的领域主席，EMNLP的资深领域主席，和Information Retrieval Journal的主编。
            </div>
        </div>
    </div>
    <div class="row">
        <div class="container">
            <div class="name-bar">Di He</div>
            <div class="institute">Peking University Intelligent College</div>
            <div class="title">Title: 是否所有大模型都具备思维链涌现能力？</div>
            <div class="abstract">
                <strong>Abstract:</strong> 国内外有许多研究工作提出多种Transformer的高效变体，但对于众多模型变体，有许多问题需要回答：这些变体模型是否存在理论缺陷？面临具体实际问题时模型结构应当如何选择？到底哪些变体模型能真正完美地取代Transformer？最近的研究发现，思维链（Chain-of-Thought）提示（CoT）可以显著提高大型语言模型（LLMs）的性能，特别是在处理涉及数学或推理的复杂任务。尽管经验上取得了巨大的成功，但CoT背后的机制以及它如何发挥LLMs的潜力仍然难以捉摸。是不是所有大模型都具备思维链推理能力？这种能力是如何涌现的？在这个talk中，我们首次尝试在理论上回答这些问题，并展示不同模型（高效Transformer v.s. 标准Transformer）的能力上限差异。
            </div>
            <div class="abstract">
                <strong>CV:</strong> 贺笛，北京大学智能学院助理教授，前微软亚洲研究院主管研究员。主要从事机器学习模型、算法与理论方向的研究工作，已发表ICML、NeurIPS、ICLR等重要期刊/会议论文50余篇，谷歌引用数超过8000，指导学生2次在图神经网络国际顶级评测竞赛上取得冠军。所设计的模型、算法多次被DeepMind、OpenAI、微软、Meta等国际顶尖研究机构使用。获得机器学习顶级国际会议ICLR 2023杰出论文奖。
            </div>
        </div>
    </div>
</body>
</html>

<style>

.tip{}

.icon {
    width: 15px;
}

.row {
    padding: 10px; 
    height: auto; 
    border-bottom-width: 2px; 
    border-style: solid; 
    border-color: #E4E7ED; 
    padding-bottom: 20px; 
    padding-top: 20px;
    display: flex; 
    text-align: justify;
}

.left {
    min-width: 150px !important;
    text-align: center;
}

.avatar {
    width: 120px;
    height: 160px;
    max-width: 100%;
    border-radius: 10px;
}

.right {
    margin-left: 10px; 
    max-width: 80%;
}


.font-small {
    /* font-size: 16px; */
}

.font-bold {
    font-weight: bold;
}
</style>